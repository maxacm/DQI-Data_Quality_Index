{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5120zm_cTcXP"
      },
      "source": [
        "# Mishra Data Quality Index 3 (p3.py)\n",
        "Max Calzada \n",
        "January 8, 2022 (Latest Update)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvnCX-g-TeZp"
      },
      "source": [
        "'dqi4_4sentences.csv' [snli_1.0_test.jsonl](https://github.com/uclnlp/inferbeddings/blob/master/data/snli/snli_1.0_test.jsonl.gz) and must be manually inserted into the content folder each session."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXn85LWRThDT"
      },
      "source": [
        "## What does DQI c3 do?\n",
        "\n",
        "DQI c3 measures Inter-Sample STS (Semantic Textual Similarity). In other words, DQI c3 measures how similar the different sentences/data are to each other. \n",
        "\n",
        "The aim is for the sentences to have a low amount of variation in similarity to each other."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Instructions\n",
        "\n",
        "DQI c3 may require some manual edits by the user, depending on the user's needs. The following steps guide the user in editing the code if necessary.\n",
        "\n",
        "### STEP 1: Hyperparameter\n",
        "\n",
        "Under the `@jit def func2():` the line of code reads `a=1`. In this case, `a=1` means that the user wants one sentence/datum to yield the minimum similarity score. \n",
        "\n",
        "If the user were to edit the code to read `a=3`, this would mean that the user wants 3 sentence/data to yield the minimum similarity score.\n",
        "\n",
        "### STEP 2: tf2\n",
        "\n",
        "If tf2 yields `None`, this means that the value of DQI c3 is only `tf1` and that `tf2` does not factor in. In this case leave code as is and ignore STEP 3.\n",
        "\n",
        "If tf2 yields a numerical value, proceed to STEP 3.\n",
        "\n",
        "### STEP 3: dqic3\n",
        "\n",
        "If tf2 yields a numerical value, comment in the lines `dqic3=tf1+tf2` and `print(dqic3)`.\n",
        "\n",
        "In this case, the value of DQI c3 will be yielded by `dqic3`."
      ],
      "metadata": {
        "id": "g4mK4Q-JZesl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJDp5xm5TNMy",
        "outputId": "390584e5-679f-4c5d-ea1c-af7867ba6746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd # Load libraries\n",
        "import numpy as np \n",
        "import json\n",
        "import csv\n",
        "\n",
        "from tqdm import tqdm \n",
        "from tqdm import tqdm_notebook as tqdm \n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import spacy\n",
        "import string\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import spacy.cli\n",
        "\n",
        "spacy.cli.download(\"en_core_web_lg\") # https://www.google.com/search?q=what+does+en_core_web_lg+do&sxsrf=ALiCzsYQ__E0ulCClCOKwhb8uwQYY1bcRw%3A1668697353810&ei=CU12Y5byMIKs5NoP-8KCyA4&ved=0ahUKEwjWmouIvrX7AhUCFlkFHXuhAOkQ4dUDCBA&uact=5&oq=what+does+en_core_web_lg+do&gs_lcp=Cgxnd3Mtd2l6LXNlcnAQAzIECAAQRzIECAAQRzIECAAQRzIECAAQRzIECAAQRzIECAAQRzIECAAQRzIECAAQRzoKCAAQRxDWBBCwA0oECEEYAEoECEYYAFD_A1j_A2DjDGgBcAJ4AIABAIgBAJIBAJgBAKABAcgBCMABAQ&sclient=gws-wiz-serp\n",
        "nlp = spacy.load(\"en_core_web_lg\") # tokenize, lemmatize, and summarize\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity \n",
        "\n",
        "from spacy.lang.en.examples import sentences  \n",
        "\n",
        "from numba import jit, cuda "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "9173bb93e0254bc7a52d47125ea77ab6",
            "5f284ff1010847dcab299351da5c205f",
            "d32b7eedeebf4be4828ea5297a889633",
            "76ad4a9409f841c2ab82874da487a9d4",
            "71c30abaeab443d08e76a8989c03b2b3",
            "0efad8906eeb4d539635b0e7f9dc06ac",
            "ba1b2b4f8f2a4580981d2f31a6bfdbd1",
            "d96db58e86714536bcf89b42b2a0b953",
            "940f204246a947a3b0655c97e10f9823",
            "f86f2355819e4874bb1f87882cf9f761",
            "9cb188913c26468180b9c865b878babe"
          ]
        },
        "id": "5JUHlKZMUK4d",
        "outputId": "eca42beb-80fa-4088-ef0b-45e75ba28a49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9c3dcdc17983>:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  words2['nopunc'] = words2['nopunc'].str.replace(\".\", \"\")\n",
            "<ipython-input-2-9c3dcdc17983>:27: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm(range(len(words2))):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9173bb93e0254bc7a52d47125ea77ab6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9c3dcdc17983>:32: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  words2['fullnopunc'] = words2['fullnopunc'].str.replace(\".\", \"\")\n"
          ]
        }
      ],
      "source": [
        "# This code was borrowed from DQI c1.\n",
        "\n",
        "df_wino = pd.read_csv('dqi4_4sentences.csv')\n",
        "words2=pd.DataFrame()\n",
        "frames=[df_wino['documents']]\n",
        "words2['full'] = pd.concat(frames)\n",
        "words2.reset_index(inplace = True) \n",
        "words2['casewords'] = words2['full'].str.lower()\n",
        "words2['wsw'] = words2['casewords'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "words2['nopunc'] = words2['wsw'].str.replace(\"'\", \"\")\n",
        "words2['nopunc'] = words2['nopunc'].str.replace(\".\", \"\")\n",
        "words2['nopunc'] = words2['nopunc'].str.replace(\",\", \"\")\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize_text(text): # finds roots of words in text\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)] \n",
        "words2['text_lemmatized'] = words2.nopunc.apply(lemmatize_text) # ISSUE : lemmatize_text # package updates?\n",
        "\n",
        "words2['final']=\"NaN\"\n",
        "def final(x):\n",
        "    makeitastring = ' '.join(map(str, x))\n",
        "    makeitastring=makeitastring.replace(\",\",\"\")\n",
        "    makeitastring=makeitastring.replace(\"'\",\"\")\n",
        "    makeitastring=makeitastring.replace(\"[\",\"\")\n",
        "    makeitastring=makeitastring.replace(\"]\",\"\")\n",
        "    return makeitastring\n",
        "for i in tqdm(range(len(words2))):    \n",
        "    column=['text_lemmatized']\n",
        "    row=[i]\n",
        "    words2.loc[i,'final']=final(words2.loc[i,'text_lemmatized'])\n",
        "words2['fullnopunc'] = words2['full'].str.replace(\"'\", \"\")\n",
        "words2['fullnopunc'] = words2['fullnopunc'].str.replace(\".\", \"\")\n",
        "words2['fullnopunc'] = words2['fullnopunc'].str.replace(\",\", \"\")\n",
        "words2['label']='NaN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VBdwPJ_UVAM"
      },
      "outputs": [],
      "source": [
        "words=pd.read_csv('dqi4_4sentences.csv')\n",
        "snlitrain_l_list = [] # empty list\n",
        "pandas_json_attempt = []\n",
        "with open('./snli_1.0_test.jsonl') as snlitrain_file_pointer: # snli_1.0_test.jsonl\n",
        "    for item in snlitrain_file_pointer: # open `snli_1.0_test.jsonl`\n",
        "        snlitrain_l_list.append(item) # `append()` places `snli_1.0_test.jsonl` items in list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNSOmJBGUV10"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for item in snlitrain_l_list:\n",
        "    data.append(json.loads(item)) # parse a valid JSON string and convert it to a Python Dictionary\n",
        "      # and appends this to `data`\n",
        "df_snlitrain = pd.DataFrame.from_dict(data) # constructs DataFrame from dict of array-like or dicts\n",
        "nlp = spacy.load(\"en_core_web_lg\") # spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
        "\n",
        "@jit\n",
        "def func():\n",
        "    x=[]\n",
        "    for l in range(len(data)-1):\n",
        "        f=0\n",
        "        token_l=nlp(data[l]) # tokenizes sentence `words`?\n",
        "        for m in range(len(data)-1): \n",
        "            if(m!=l): # different sentence\n",
        "                token_m=nlp(data[m]) # tokenizes another sentences\n",
        "                slm=token_l.similarity(token_m) # measures similarity be                   \n",
        "                diff=SIML-slm # subracts similarity of two sentences from threshold.\n",
        "                if(diff<=0):\n",
        "                    f=f+1\n",
        "        x.append(f)\n",
        "    t = pd.Series(x)\n",
        "    tf1=t.var()\n",
        "    return tf1\n",
        "\n",
        "@jit\n",
        "def amaxelements(list1, N): # creates variables `list1` and `N`.\n",
        "    sa=0\n",
        "    for i in range(0, N):\n",
        "        max1 = 0  \n",
        "        for j in range(len(list1)):\n",
        "            if list1[j] > max1: \n",
        "                max1 = list1[j]; \n",
        "        list1.remove(max1); \n",
        "        sa=sa+max1\n",
        "    return sa\n",
        "\n",
        "# STEP 1: Set hyperparameter `a=` to many sentences should have the minimum simialrity score\n",
        "@jit\n",
        "def func2():\n",
        "    a=1 # Hyperparameter\n",
        "    sl=0\n",
        "    for l in range(len(data)-1):\n",
        "        x=[] # empty set\n",
        "        token_l=nlp(data[l]) # tokenizes sentences\n",
        "        for m in range(len(data)-1): \n",
        "            if(m!=l): # different sentence\n",
        "                token_m=nlp(data[m]) \n",
        "                slm=token_l.similarity(token_m) # similarity                \n",
        "                diff1=SIML-slm \n",
        "                diff2=abs(diff1)\n",
        "                diff=abs(diff1-diff2)\n",
        "                x.append(diff) # x creates vector/list of differences\n",
        "        sl=sl+amaxelements(x,a)\n",
        "    tf2=sl/5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words2['final']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eejiJGXbZYRz",
        "outputId": "2f9f2911-48e5-4f74-d889-45bdda8b9735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    solubility measurement correlation Ã®Âµ-2 4 6 8 ...\n",
              "1    combustion behavior flame structure high energ...\n",
              "2    effect particle size thermal decomposition clÃ¢...\n",
              "3    Ã¯Â»Â¿energetic characteristic calculation new ge...\n",
              "Name: final, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mokuW8a3U4aw",
        "outputId": "eda8eb72-06f2-4f00-b411-d8d6656210dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-11bb4ef93c50>:8: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"func\" failed type inference due to: Untyped global name 'data': Cannot determine Numba type of <class 'pandas.core.series.Series'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 11:\n",
            "def func():\n",
            "    <source elided>\n",
            "    x=[]\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): #\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-23-11bb4ef93c50>:8: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"func\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 11:\n",
            "def func():\n",
            "    <source elided>\n",
            "    x=[]\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): #\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"func\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 10:\n",
            "def func():\n",
            "    x=[]\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 10:\n",
            "def func():\n",
            "    x=[]\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "<ipython-input-23-11bb4ef93c50>:8: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"func\" failed type inference due to: Untyped global name 'data': Cannot determine Numba type of <class 'pandas.core.series.Series'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 11:\n",
            "def func():\n",
            "    <source elided>\n",
            "    x=[]\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): #\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"func\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 11:\n",
            "def func():\n",
            "    <source elided>\n",
            "    x=[]\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): #\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 11:\n",
            "def func():\n",
            "    <source elided>\n",
            "    x=[]\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): #\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-11bb4ef93c50>:39: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"func2\" failed type inference due to: Untyped global name 'data': Cannot determine Numba type of <class 'pandas.core.series.Series'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 43:\n",
            "def func2():\n",
            "    <source elided>\n",
            "    sl=0\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): # \n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-23-11bb4ef93c50>:39: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"func2\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 43:\n",
            "def func2():\n",
            "    <source elided>\n",
            "    sl=0\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): # \n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"func2\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 41:\n",
            "def func2():\n",
            "    a=1 # \n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 41:\n",
            "def func2():\n",
            "    a=1 # \n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "<ipython-input-23-11bb4ef93c50>:39: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"func2\" failed type inference due to: Untyped global name 'data': Cannot determine Numba type of <class 'pandas.core.series.Series'>\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 43:\n",
            "def func2():\n",
            "    <source elided>\n",
            "    sl=0\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): # \n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"func2\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 43:\n",
            "def func2():\n",
            "    <source elided>\n",
            "    sl=0\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): # \n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 43:\n",
            "def func2():\n",
            "    <source elided>\n",
            "    sl=0\n",
            "    for l in range(len(data)-1): # tqdm(range(len(data)-1)): # \n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'list1' of function 'amaxelements'.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"<ipython-input-23-11bb4ef93c50>\", line 27:\n",
            "@jit\n",
            "def amaxelements(list1, N): # creates variables `list1` and `N`.\n",
            "^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/ir_utils.py:2147: NumbaPendingDeprecationWarning: \n",
            "Encountered the use of a type that is scheduled for deprecation: type 'reflected list' found for argument 'lst' of function 'list_remove.<locals>.list_remove_impl'.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-reflection-for-list-and-set-types\n",
            "\n",
            "File \"../usr/local/lib/python3.8/dist-packages/numba/cpython/listobj.py\", line 1028:\n",
            "\n",
            "    def list_remove_impl(lst, value):\n",
            "    ^\n",
            "\n",
            "  warnings.warn(NumbaPendingDeprecationWarning(msg, loc=loc))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "data=words2['final']\n",
        "SIML=0.8\n",
        "\n",
        "tf1 = func()\n",
        "print(tf1) \n",
        "\n",
        "# STEP 2: If tf2 yields \"None\", leave code as is and ignore STEP 3.\n",
        "#   If tf2 yields a numerical value, proceed to STEP 3.\n",
        "tf2 = func2()\n",
        "print(tf2)\n",
        "\n",
        "# # STEP 3: Comment in the following two lines.\n",
        "# dqic3=tf1+tf2\n",
        "# print(dqic3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqsz24NLhF_f"
      },
      "source": [
        "## How should the DQI c3 results be interpreted?\n",
        "\n",
        "`dqi4_4sentences.csv` yielded values of `0` and `None`. In a sense, `0 + None = 0`.\n",
        "\n",
        "In his paper, Mishra classified values at 14.3370 and below as \"good\" and values at and above 16.7024 as \"bad\", meaning that the value of 0 is classified as \"good\".\n",
        "\n",
        "In the case of `dqi4_4sentences.csv`, this means that its sentences/data are all very distinct from each other."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9173bb93e0254bc7a52d47125ea77ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f284ff1010847dcab299351da5c205f",
              "IPY_MODEL_d32b7eedeebf4be4828ea5297a889633",
              "IPY_MODEL_76ad4a9409f841c2ab82874da487a9d4"
            ],
            "layout": "IPY_MODEL_71c30abaeab443d08e76a8989c03b2b3"
          }
        },
        "5f284ff1010847dcab299351da5c205f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0efad8906eeb4d539635b0e7f9dc06ac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ba1b2b4f8f2a4580981d2f31a6bfdbd1",
            "value": "100%"
          }
        },
        "d32b7eedeebf4be4828ea5297a889633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96db58e86714536bcf89b42b2a0b953",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_940f204246a947a3b0655c97e10f9823",
            "value": 4
          }
        },
        "76ad4a9409f841c2ab82874da487a9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f86f2355819e4874bb1f87882cf9f761",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9cb188913c26468180b9c865b878babe",
            "value": " 4/4 [00:00&lt;00:00, 127.68it/s]"
          }
        },
        "71c30abaeab443d08e76a8989c03b2b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0efad8906eeb4d539635b0e7f9dc06ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1b2b4f8f2a4580981d2f31a6bfdbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d96db58e86714536bcf89b42b2a0b953": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940f204246a947a3b0655c97e10f9823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f86f2355819e4874bb1f87882cf9f761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb188913c26468180b9c865b878babe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}