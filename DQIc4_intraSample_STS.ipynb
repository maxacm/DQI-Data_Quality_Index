{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mishra Data Quality Index 4 (p4g.py)\n",
        "Max Calzada \n",
        "January 6, 2023 (Latest Update)"
      ],
      "metadata": {
        "id": "D9UHKwveDBFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'dqi4_4sentences.csv' or NLP sentences to be analyzed must be manually inserted into the content folder each session.\n",
        "\n",
        "To analyze NLP data, command `gwords=pd.read_csv(\"dqi4_4sentences.csv\")` must be edited so that the argument in the `pd.read_csv()` command matches the name of the data set."
      ],
      "metadata": {
        "id": "onHHemLXCkQA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What does DQI c4 do?\n",
        "\n",
        "DQI c4 measures intra-sample word similarity, or the word similarity within each sentence or datum.\n",
        "\n",
        "The closer the average similarity score is towards the minimum value, the higher the data quality."
      ],
      "metadata": {
        "id": "dLvHohwHChO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Appropriate Data Format\n",
        "\n",
        "To read in NLP data, make sure that the data is in a .csv format. The data should only have one column titled `documents`. Each cell should contain one datum."
      ],
      "metadata": {
        "id": "mQKinTc3Cdkm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kKNq6QN_Aen",
        "outputId": "88fd4240-5244-4d47-e2f8-440a2854d795"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import json\n",
        "import csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm # issue with tqdm?\n",
        "from tqdm import tqdm_notebook as tqdm # needed? # correct?\n",
        "# Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import nltk\n",
        "# nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import spacy\n",
        "import math\n",
        "\n",
        "import string\n",
        "import sys\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "import spacy.cli\n",
        "\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "nlp = spacy.load(\"en_core_web_lg\") # spacy.load(\"en_trf_bertbaseuncased_lg\") #\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from spacy.lang.en.examples import sentences # needed?\n",
        "\n",
        "from numba import jit, cuda"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gwords=pd.read_csv(\"dqi4_4sentences.csv\") # pd.read_csv(\"path_to_dev_good_words/dev_good_words.csv\")\n",
        "\n",
        "@jit\n",
        "def parameter4(sentence,size,WSIML):\n",
        "    lists=[]\n",
        "    vals=[]\n",
        "    for x in range(len(sentence)): # tqdm(range(len(sentence))):\n",
        "        arr=[]\n",
        "        s=sentence[x]\n",
        "        word = s.split() # splits string into a list\n",
        "        length=len(word)\n",
        "        sl=0 # should I make these start at 1?\n",
        "        for i in (range(length)):\n",
        "            sm=0\n",
        "            token_l=nlp(word[i])\n",
        "            for j in (range(length)):\n",
        "                if(i!=j):\n",
        "                    token_m=nlp(word[j])\n",
        "                    sm=sm+token_l.similarity(token_m)\n",
        "            sm=sm/length\n",
        "            arr.append(sm)\n",
        "            sm=abs(sm-WSIML)\n",
        "            sl=sl+sm\n",
        "        lists.append(arr)\n",
        "        vals.append(size/sl)\n",
        "    dqic4_df_lists=pd.DataFrame(lists) # df=pd.DataFrame(lists)\n",
        "    dqic4_df_lists.to_csv(\"dqic4_df_lists.csv\")\n",
        "    # df.to_csv(\"path_to_wordsimgsabs/wordsimgabs.csv\") # how do I direct .csvs?\n",
        "    dqic4_df_vals=pd.DataFrame(vals) # df=pd.DataFrame(vals)\n",
        "    dqic4_df_vals.to_csv(\"dqic4_df_vals.csv\")\n",
        "    # df.to_csv(\"path_to_dqic4gabs/dqic4gabs.csv\") # ?"
      ],
      "metadata": {
        "id": "di7_Z02l_JKh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size=len(gwords)-1\n",
        "WSIML=0.5\n",
        "sentence=gwords['documents'] # gwords['fullnopunc'] # code requires only one column\n",
        "parameter4(sentence,size,WSIML)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3t3YW80_OuC",
        "outputId": "f0f4472a-a715-4d6b-91d7-7c5341d0c5c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-1c430fdae79a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITH looplifting enabled because Function \"parameter4\" failed type inference due to: Untyped global name 'nlp': Cannot determine Numba type of <class 'spacy.lang.en.English'>\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 15:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    <source elided>\n",
            "            sm=0\n",
            "            token_l=nlp(word[i])\n",
            "            ^\n",
            "\n",
            "  @jit\n",
            "<ipython-input-2-1c430fdae79a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parameter4\" failed type inference due to: Cannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 7:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    <source elided>\n",
            "    vals=[]\n",
            "    for x in range(len(sentence)): # tqdm(range(len(sentence))):\n",
            "    ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"parameter4\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 5:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    lists=[]\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 5:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    lists=[]\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "<ipython-input-2-1c430fdae79a>:3: NumbaWarning: \n",
            "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"parameter4\" failed type inference due to: Untyped global name 'nlp': Cannot determine Numba type of <class 'spacy.lang.en.English'>\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 15:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    <source elided>\n",
            "            sm=0\n",
            "            token_l=nlp(word[i])\n",
            "            ^\n",
            "\n",
            "  @jit\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:151: NumbaWarning: Function \"parameter4\" was compiled in object mode without forceobj=True.\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 7:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    <source elided>\n",
            "    vals=[]\n",
            "    for x in range(len(sentence)): # tqdm(range(len(sentence))):\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
            "/usr/local/lib/python3.8/dist-packages/numba/core/object_mode_passes.py:161: NumbaDeprecationWarning: \n",
            "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
            "\n",
            "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
            "\n",
            "File \"<ipython-input-2-1c430fdae79a>\", line 7:\n",
            "def parameter4(sentence,size,WSIML):\n",
            "    <source elided>\n",
            "    vals=[]\n",
            "    for x in range(len(sentence)): # tqdm(range(len(sentence))):\n",
            "    ^\n",
            "\n",
            "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
            "<ipython-input-3-690e558a8d84>:4: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  parameter4(sentence,size,WSIML)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How should the DQI c4 results be interpreted?\n",
        "\n",
        "The numbers in each row of `dqic4_df_lists` are the similarity scores comparing two differents word in the same sentence. The scores in the single column of `dqic4_df_vals` are the averages across their corresponding rows in `dqic4_df_lists`. \n",
        "\n",
        "In his paper, Mishra categorizes values for `dqic4_df_vals` at or above 0.000372 as \"good\" and values at or below 0.000062 as \"bad.\""
      ],
      "metadata": {
        "id": "9TSmcaF9DJoV"
      }
    }
  ]
}